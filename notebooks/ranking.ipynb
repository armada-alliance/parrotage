{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/waelivie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/waelivie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import mendable as md\n",
    "import dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import requests\n",
    "import asyncio\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Might need this later\n",
    "# MENDABLE_API_KEY = os.getenv(\"MENDABLE_API_KEY_SPO_TOOL\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the SEADOG model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to first get all the answers from telegram chat csv file and separate the questions and answers. I think the solution I can try to do this is to use nltk library to help determine each. I have googled and thought of a few words that can be used to determine if the sentence is a question or answer to a question. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have the words in arrays, we can now use that to determine if the sentence is a question or answer from our telegram chat csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_chat_df = pd.read_csv(\"armada_chat_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>message_id</th>\n",
       "      <th>reply</th>\n",
       "      <th>reply_to_message_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>655534778</td>\n",
       "      <td>Found it... clearly didn't search very hard ba...</td>\n",
       "      <td>2023-12-12 22:42:15+00:00</td>\n",
       "      <td>57624</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>655534778</td>\n",
       "      <td>Hey yes I gave it a go to fix my SSD issue. Un...</td>\n",
       "      <td>2023-12-12 22:24:50+00:00</td>\n",
       "      <td>57623</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MessageReplyHeader(reply_to_scheduled=False, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2076101368</td>\n",
       "      <td>lol I agree</td>\n",
       "      <td>2023-12-12 21:56:40+00:00</td>\n",
       "      <td>57622</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>635318013</td>\n",
       "      <td>Just gotta wait past 35 hours</td>\n",
       "      <td>2023-12-12 21:55:37+00:00</td>\n",
       "      <td>57621</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>635318013</td>\n",
       "      <td>But for the most part, it's mostly stable now</td>\n",
       "      <td>2023-12-12 21:55:27+00:00</td>\n",
       "      <td>57620</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>6137081769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-23 05:36:52+00:00</td>\n",
       "      <td>55587</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>1474655618</td>\n",
       "      <td>Would also appreciate a critical review for th...</td>\n",
       "      <td>2023-07-21 20:35:43+00:00</td>\n",
       "      <td>55586</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>1474655618</td>\n",
       "      <td>https://docs.google.com/document/d/1bSNKml6JW-...</td>\n",
       "      <td>2023-07-21 20:35:28+00:00</td>\n",
       "      <td>55585</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>1474655618</td>\n",
       "      <td>Question for you guys, I’m working on a new co...</td>\n",
       "      <td>2023-07-21 20:35:17+00:00</td>\n",
       "      <td>55584</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>5808666251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-20 17:39:18+00:00</td>\n",
       "      <td>55583</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   sender_id  \\\n",
       "0              0   655534778   \n",
       "1              1   655534778   \n",
       "2              2  2076101368   \n",
       "3              3   635318013   \n",
       "4              4   635318013   \n",
       "...          ...         ...   \n",
       "1995        1995  6137081769   \n",
       "1996        1996  1474655618   \n",
       "1997        1997  1474655618   \n",
       "1998        1998  1474655618   \n",
       "1999        1999  5808666251   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Found it... clearly didn't search very hard ba...   \n",
       "1     Hey yes I gave it a go to fix my SSD issue. Un...   \n",
       "2                                           lol I agree   \n",
       "3                         Just gotta wait past 35 hours   \n",
       "4         But for the most part, it's mostly stable now   \n",
       "...                                                 ...   \n",
       "1995                                                NaN   \n",
       "1996  Would also appreciate a critical review for th...   \n",
       "1997  https://docs.google.com/document/d/1bSNKml6JW-...   \n",
       "1998  Question for you guys, I’m working on a new co...   \n",
       "1999                                                NaN   \n",
       "\n",
       "                           date  message_id reply  \\\n",
       "0     2023-12-12 22:42:15+00:00       57624    No   \n",
       "1     2023-12-12 22:24:50+00:00       57623   Yes   \n",
       "2     2023-12-12 21:56:40+00:00       57622    No   \n",
       "3     2023-12-12 21:55:37+00:00       57621    No   \n",
       "4     2023-12-12 21:55:27+00:00       57620    No   \n",
       "...                         ...         ...   ...   \n",
       "1995  2023-07-23 05:36:52+00:00       55587    No   \n",
       "1996  2023-07-21 20:35:43+00:00       55586    No   \n",
       "1997  2023-07-21 20:35:28+00:00       55585    No   \n",
       "1998  2023-07-21 20:35:17+00:00       55584    No   \n",
       "1999  2023-07-20 17:39:18+00:00       55583    No   \n",
       "\n",
       "                                    reply_to_message_id  \n",
       "0                                                   NaN  \n",
       "1     MessageReplyHeader(reply_to_scheduled=False, f...  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "1995                                                NaN  \n",
       "1996                                                NaN  \n",
       "1997                                                NaN  \n",
       "1998                                                NaN  \n",
       "1999                                                NaN  \n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_chat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first column\n",
    "tg_chat_df = tg_chat_df.drop(tg_chat_df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MessageReplyHeader(reply_to_scheduled=False, forum_topic=False, quote=False, reply_to_msg_id=57582, reply_to_peer_id=None, reply_from=None, reply_media=None, reply_to_top_id=49888, quote_text=None, quote_entities=[], quote_offset=None)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_chat_df['reply_to_message_id'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are dropping all NaN rows in the text column from the data set\n",
    "tg_chat_df = tg_chat_df.dropna(subset=['text'])\n",
    "\n",
    "# Reset the index\n",
    "tg_chat_df = tg_chat_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>message_id</th>\n",
       "      <th>reply</th>\n",
       "      <th>reply_to_message_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>655534778</td>\n",
       "      <td>Found it... clearly didn't search very hard ba...</td>\n",
       "      <td>2023-12-12 22:42:15+00:00</td>\n",
       "      <td>57624</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655534778</td>\n",
       "      <td>Hey yes I gave it a go to fix my SSD issue. Un...</td>\n",
       "      <td>2023-12-12 22:24:50+00:00</td>\n",
       "      <td>57623</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MessageReplyHeader(reply_to_scheduled=False, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2076101368</td>\n",
       "      <td>lol I agree</td>\n",
       "      <td>2023-12-12 21:56:40+00:00</td>\n",
       "      <td>57622</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>635318013</td>\n",
       "      <td>Just gotta wait past 35 hours</td>\n",
       "      <td>2023-12-12 21:55:37+00:00</td>\n",
       "      <td>57621</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>635318013</td>\n",
       "      <td>But for the most part, it's mostly stable now</td>\n",
       "      <td>2023-12-12 21:55:27+00:00</td>\n",
       "      <td>57620</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>5403145942</td>\n",
       "      <td>everything is fine, except block propagation d...</td>\n",
       "      <td>2023-07-23 22:19:31+00:00</td>\n",
       "      <td>55589</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>5403145942</td>\n",
       "      <td>Hi @WCat13 I got my metrics back! You were rig...</td>\n",
       "      <td>2023-07-23 22:16:20+00:00</td>\n",
       "      <td>55588</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1474655618</td>\n",
       "      <td>Would also appreciate a critical review for th...</td>\n",
       "      <td>2023-07-21 20:35:43+00:00</td>\n",
       "      <td>55586</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>1474655618</td>\n",
       "      <td>https://docs.google.com/document/d/1bSNKml6JW-...</td>\n",
       "      <td>2023-07-21 20:35:28+00:00</td>\n",
       "      <td>55585</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>1474655618</td>\n",
       "      <td>Question for you guys, I’m working on a new co...</td>\n",
       "      <td>2023-07-21 20:35:17+00:00</td>\n",
       "      <td>55584</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1904 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sender_id                                               text  \\\n",
       "0      655534778  Found it... clearly didn't search very hard ba...   \n",
       "1      655534778  Hey yes I gave it a go to fix my SSD issue. Un...   \n",
       "2     2076101368                                        lol I agree   \n",
       "3      635318013                      Just gotta wait past 35 hours   \n",
       "4      635318013      But for the most part, it's mostly stable now   \n",
       "...          ...                                                ...   \n",
       "1899  5403145942  everything is fine, except block propagation d...   \n",
       "1900  5403145942  Hi @WCat13 I got my metrics back! You were rig...   \n",
       "1901  1474655618  Would also appreciate a critical review for th...   \n",
       "1902  1474655618  https://docs.google.com/document/d/1bSNKml6JW-...   \n",
       "1903  1474655618  Question for you guys, I’m working on a new co...   \n",
       "\n",
       "                           date  message_id reply  \\\n",
       "0     2023-12-12 22:42:15+00:00       57624    No   \n",
       "1     2023-12-12 22:24:50+00:00       57623   Yes   \n",
       "2     2023-12-12 21:56:40+00:00       57622    No   \n",
       "3     2023-12-12 21:55:37+00:00       57621    No   \n",
       "4     2023-12-12 21:55:27+00:00       57620    No   \n",
       "...                         ...         ...   ...   \n",
       "1899  2023-07-23 22:19:31+00:00       55589    No   \n",
       "1900  2023-07-23 22:16:20+00:00       55588    No   \n",
       "1901  2023-07-21 20:35:43+00:00       55586    No   \n",
       "1902  2023-07-21 20:35:28+00:00       55585    No   \n",
       "1903  2023-07-21 20:35:17+00:00       55584    No   \n",
       "\n",
       "                                    reply_to_message_id  \n",
       "0                                                   NaN  \n",
       "1     MessageReplyHeader(reply_to_scheduled=False, f...  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "1899                                                NaN  \n",
       "1900                                                NaN  \n",
       "1901                                                NaN  \n",
       "1902                                                NaN  \n",
       "1903                                                NaN  \n",
       "\n",
       "[1904 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_chat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Found it... clearly didn't search very hard ba...\n",
       "1      Hey yes I gave it a go to fix my SSD issue. Un...\n",
       "2                                            lol I agree\n",
       "3                          Just gotta wait past 35 hours\n",
       "4          But for the most part, it's mostly stable now\n",
       "                             ...                        \n",
       "995    Oh I spoke to whoever runs the Twitter and the...\n",
       "996    We can also add audio which is sort of rare. M...\n",
       "997    Any pool here want to use the AA space on http...\n",
       "998    Down and starting again so could be hours befo...\n",
       "999    Both relays are down and starting at the momen...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_chat_df['text'][:1000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so how can I rank the questions or find a way to determine the most meaningful questions.... I am currently going to try and just check frequency a question or similar questions are asked.\n",
    "\n",
    "I am not sure what project to use to help with my project. There are a few things I am thinking of using and I have a certain strategy in mind.\n",
    "\n",
    "\n",
    "Developing a program to filter and rank valuable questions and answers from a chat group using the Telegram API is a multifaceted task. Your current approach, based on identifying questions and answers through keywords, is a good start. However, there are several other techniques and considerations that can enhance the efficacy of your program:\n",
    "\n",
    "1. **Natural Language Processing (NLP):** \n",
    "   - **Sentiment Analysis:** Identify the tone of the messages. Positive or informative responses could be more valuable.\n",
    "   - **Named Entity Recognition (NER):** Extract names, places, organizations, etc., from the text. This can help in categorizing questions and answers.\n",
    "   - **Topic Modeling:** Use algorithms like Latent Dirichlet Allocation (LDA) to find topics within the text data. This can help in clustering similar questions and answers.\n",
    "   - **Language Modeling:** Use models like BERT or GPT to understand the context of the conversation better.\n",
    "\n",
    "2. **Question and Answer Matching:**\n",
    "   - Develop a system to match questions with their most relevant answers.\n",
    "   - Use cosine similarity or other text similarity measures to find answers that are most relevant to a given question.\n",
    "\n",
    "3. **Ranking Algorithm:**\n",
    "   - Implement a ranking algorithm that takes into account various factors like the length of the answer, the number of upvotes (if available), and the relevance to the question.\n",
    "   - Consider using machine learning models to predict the usefulness of an answer based on historical data.\n",
    "\n",
    "4. **User Feedback Integration:**\n",
    "   - If possible, incorporate user feedback like upvotes, downvotes, or comments to understand the value of questions and answers.\n",
    "   - Use this feedback as a part of the training data for your machine learning models.\n",
    "\n",
    "5. **Data Preprocessing:**\n",
    "   - Clean the data by removing irrelevant content, such as advertisements or off-topic messages.\n",
    "   - Normalize text data by lowercasing, removing punctuation, and correcting typos.\n",
    "\n",
    "6. **Handling Ambiguity and Sarcasm:**\n",
    "   - This is a challenging aspect, but advanced NLP techniques and contextual understanding can help in identifying such nuances.\n",
    "\n",
    "7. **Testing and Validation:**\n",
    "   - Regularly test your model with new data and validate its effectiveness.\n",
    "   - Consider using A/B testing to compare different models or algorithms.\n",
    "\n",
    "8. **Scalability:**\n",
    "   - Ensure your solution can handle large amounts of data without significant performance issues.\n",
    "   - Optimize database queries and use efficient data structures.\n",
    "\n",
    "9. **Ethical and Privacy Considerations:**\n",
    "   - Ensure that the data usage complies with privacy laws and ethical standards.\n",
    "   - Anonymize personal data where necessary.\n",
    "\n",
    "10. **Continuous Learning and Updating:**\n",
    "    - Regularly update your model with new data.\n",
    "    - Consider implementing a feedback loop where the model learns from its successes and mistakes.\n",
    "\n",
    "Remember, the effectiveness of these methods can vary based on the specific characteristics of your data and the nature of the chat group. Experimentation and iterative improvements will be key to developing a robust solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def is_question(text):\n",
    "    # Create a TextBlob from the input text\n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    # Access the tags property for part-of-speech tagging\n",
    "    tags = blob.tags\n",
    "    \n",
    "    # Check if the text contains any words tagged as WH-pronouns\n",
    "    question_words = ['WDT', 'WP', 'WP$', 'WRB']\n",
    "\n",
    "    return any(tag[1] in question_words for tag in tags)\n",
    "\n",
    "\n",
    "def is_answer(text):\n",
    "    # Create a TextBlob from the input text\n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    # Access the tags\n",
    "    tags = blob.tags\n",
    "    \n",
    "    # Check if the text contains characteristics indicative of answers\n",
    "    answer_indicators = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',  # Verb forms\n",
    "                         'PRP', 'PRP$', 'DT', 'IN']  # maybe not needed lmao\n",
    "                         \n",
    "    return any(tag[1] in answer_indicators for tag in tags) and len(blob.sentences) > 0\n",
    "\n",
    "# Random shit\n",
    "# test_results_answers = {text: is_answer(text) for text in tg_chat_df_sample['text']}\n",
    "# answers = [text for text, answer in test_results_answers.items() if answer == True]\n",
    "\n",
    "results = []\n",
    "# store the results in a dictionary\n",
    "for message in range(len(tg_chat_df)):\n",
    "    # print(tg_chat_df['text'][message], tg_chat_df['sender_id'][message], is_question(tg_chat_df['text'][message]))\n",
    "    q = is_question(tg_chat_df['text'][message])\n",
    "    a = is_answer(tg_chat_df['text'][message])\n",
    "    results.append({\"is_question\":q, \"is_answer\":a,\n",
    "                    \"is_reply\":tg_chat_df['reply'][message],\n",
    "                    \"message\":tg_chat_df['text'][message], \n",
    "                    \"sender_id\":tg_chat_df['sender_id'][message],\n",
    "                    \"message_id\":tg_chat_df['message_id'][message],\n",
    "                    \"reply_to_message_id\":tg_chat_df['reply_to_message_id'][message],\n",
    "                    \"date\":tg_chat_df['date'][message],\n",
    "                    })\n",
    "\n",
    "# create a dataframe from the results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/qxx0f2_j4pd9p5_p096pjflw0000gn/T/ipykernel_18804/122245910.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['processed_text'] = df['message'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Load your DataFrame just questions\n",
    "df = results_df[results_df['is_question'] == True]\n",
    "# Preprocess text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [ps.stem(word.lower()) for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    return words\n",
    "\n",
    "df['processed_text'] = df['message'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary\n",
    "dictionary = corpora.Dictionary(df['processed_text'])\n",
    "\n",
    "# Create a corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in df['processed_text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'behaviour'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.026*\"reward\" + 0.020*\"sure\" + 0.015*\"run\" + 0.015*\"look\" + 0.015*\"drop\"')\n",
      "(1, '0.027*\"vote\" + 0.018*\"happen\" + 0.014*\"block\" + 0.014*\"need\" + 0.014*\"random\"')\n",
      "(2, '0.026*\"get\" + 0.021*\"arm\" + 0.021*\"tri\" + 0.017*\"label\" + 0.017*\"scrape\"')\n",
      "(3, '0.023*\"readjsonfromfil\" + 0.018*\"import\" + 0.018*\"build\" + 0.014*\"u\" + 0.014*\"much\"')\n",
      "(4, '0.032*\"depend\" + 0.032*\"tri\" + 0.018*\"version\" + 0.016*\"goal\" + 0.014*\"reject\"')\n",
      "(5, '0.016*\"pool\" + 0.014*\"mine\" + 0.010*\"look\" + 0.010*\"one\" + 0.010*\"miss\"')\n",
      "(6, '0.051*\"see\" + 0.021*\"happen\" + 0.017*\"build\" + 0.016*\"thank\" + 0.014*\"let\"')\n",
      "(7, '0.036*\"look\" + 0.029*\"btc\" + 0.022*\"etf\" + 0.022*\"like\" + 0.015*\"profit\"')\n",
      "(8, '0.023*\"want\" + 0.019*\"like\" + 0.019*\"run\" + 0.019*\"tri\" + 0.014*\"make\"')\n",
      "(9, '0.024*\"need\" + 0.020*\"tri\" + 0.016*\"well\" + 0.016*\"one\" + 0.012*\"relay\"')\n",
      "(10, '0.016*\"compil\" + 0.016*\"iohk\" + 0.011*\"scrypt\" + 0.011*\"librari\" + 0.011*\"someon\"')\n",
      "(11, '0.023*\"file\" + 0.018*\"show\" + 0.014*\"think\" + 0.014*\"want\" + 0.014*\"may\"')\n",
      "(12, '0.026*\"relay\" + 0.023*\"know\" + 0.023*\"block\" + 0.019*\"want\" + 0.015*\"next\"')\n",
      "(13, '0.035*\"use\" + 0.034*\"know\" + 0.017*\"tri\" + 0.014*\"cabal\" + 0.014*\"let\"')\n",
      "(14, '0.024*\"use\" + 0.021*\"built\" + 0.018*\"build\" + 0.018*\"flag\" + 0.018*\"go\"')\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Set the number of topics\n",
    "num_topics = 15\n",
    "\n",
    "# Build the LDA model\n",
    "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=100)\n",
    "\n",
    "# Print the topics\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we have a lot of work to do. In order to get the topics if we intend to use topics. I am going to reseach some other strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
